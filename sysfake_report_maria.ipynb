{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c14b84e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afbba1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/tle01/Downloads/human_texts - human_texts.tsv', sep='\\t', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41561979",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['id', 'label', 'category', 'url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fb1e5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Commentary', 'False News', 'Persuasive Content', 'Polarized',\n",
       "        'Real News', 'Satire'], dtype=object),\n",
       " array([6, 5, 6, 6, 6, 6]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['category'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3b5890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_url_df = pd.read_csv('/Users/tle01/Downloads/text_url.tsv', sep='\\t', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "247ee37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2text = {}\n",
    "for text, url in zip(text_url_df['text'].values, text_url_df['url'].values):\n",
    "    url2text[url] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d5cee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = df['url'].values\n",
    "labels = df['label'].values\n",
    "for url in urls:\n",
    "    assert url in url2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9da8f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "files = glob.glob('/Users/tle01/Downloads/predictions/*.csv')\n",
    "model2preds = {}\n",
    "for file in files:\n",
    "    if 'human_texts' in file:\n",
    "        tmp = pd.read_csv(file)\n",
    "        url2pred = {}\n",
    "        for url, pred in zip(tmp['url'].values, tmp['predicted'].values):\n",
    "            url2pred[url] = pred\n",
    "        model = os.path.basename(file).replace('.csv','')\n",
    "        model2preds[model] = url2pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a5f8d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2idx = {\n",
    "    1: 'real',\n",
    "    2: 'fake',\n",
    "    3: 'opinion',\n",
    "    5: 'polarized',\n",
    "    7: 'satire',\n",
    "    9: 'promotional'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61be9636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human_texts_sgd-BERT_10051744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        real       0.50      0.17      0.25         6\n",
      "        fake       0.33      0.20      0.25         5\n",
      "     opinion       0.16      0.50      0.24         6\n",
      "   polarized       0.25      0.17      0.20         6\n",
      "      satire       0.67      0.33      0.44         6\n",
      " promotional       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.34        35\n",
      "   macro avg       0.48      0.34      0.36        35\n",
      "weighted avg       0.49      0.34      0.37        35\n",
      "\n",
      "human_texts_sgd-taxonomy_10051737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        real       0.40      0.67      0.50         6\n",
      "        fake       0.15      0.40      0.22         5\n",
      "     opinion       0.80      0.67      0.73         6\n",
      "   polarized       0.43      0.50      0.46         6\n",
      "      satire       0.00      0.00      0.00         6\n",
      " promotional       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.37        35\n",
      "   macro avg       0.30      0.37      0.32        35\n",
      "weighted avg       0.30      0.37      0.32        35\n",
      "\n",
      "human_texts_sgd-tfidf_10051745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        real       0.67      0.33      0.44         6\n",
      "        fake       0.25      0.20      0.22         5\n",
      "     opinion       0.00      0.00      0.00         6\n",
      "   polarized       0.20      0.33      0.25         6\n",
      "      satire       0.67      0.33      0.44         6\n",
      " promotional       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.31        35\n",
      "   macro avg       0.43      0.31      0.35        35\n",
      "weighted avg       0.44      0.31      0.35        35\n",
      "\n",
      "human_texts_sgd-taxonomy_10051745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        real       0.40      0.67      0.50         6\n",
      "        fake       0.15      0.40      0.22         5\n",
      "     opinion       0.80      0.67      0.73         6\n",
      "   polarized       0.43      0.50      0.46         6\n",
      "      satire       0.00      0.00      0.00         6\n",
      " promotional       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.37        35\n",
      "   macro avg       0.30      0.37      0.32        35\n",
      "weighted avg       0.30      0.37      0.32        35\n",
      "\n",
      "human_texts_svc-taxonomy_10051752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        real       0.38      0.50      0.43         6\n",
      "        fake       0.22      1.00      0.36         5\n",
      "     opinion       1.00      0.67      0.80         6\n",
      "   polarized       0.00      0.00      0.00         6\n",
      "      satire       0.00      0.00      0.00         6\n",
      " promotional       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.34        35\n",
      "   macro avg       0.27      0.36      0.26        35\n",
      "weighted avg       0.27      0.34      0.26        35\n",
      "\n",
      "human_texts_ksgd-taxonomy_rbf_10051741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        real       0.40      0.67      0.50         6\n",
      "        fake       0.24      1.00      0.38         5\n",
      "     opinion       1.00      0.67      0.80         6\n",
      "   polarized       0.00      0.00      0.00         6\n",
      "      satire       0.00      0.00      0.00         6\n",
      " promotional       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.37        35\n",
      "   macro avg       0.27      0.39      0.28        35\n",
      "weighted avg       0.27      0.37      0.28        35\n",
      "\n",
      "human_texts_svc-bert_10051748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        real       0.67      0.33      0.44         6\n",
      "        fake       0.40      0.40      0.40         5\n",
      "     opinion       0.00      0.00      0.00         6\n",
      "   polarized       0.40      0.33      0.36         6\n",
      "      satire       0.50      0.67      0.57         6\n",
      " promotional       0.60      1.00      0.75         6\n",
      "\n",
      "    accuracy                           0.46        35\n",
      "   macro avg       0.43      0.46      0.42        35\n",
      "weighted avg       0.43      0.46      0.42        35\n",
      "\n",
      "human_texts_ksgd-BERT_10051740\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        real       1.00      0.50      0.67         6\n",
      "        fake       0.33      0.20      0.25         5\n",
      "     opinion       0.00      0.00      0.00         6\n",
      "   polarized       1.00      0.17      0.29         6\n",
      "      satire       0.35      1.00      0.52         6\n",
      " promotional       0.67      1.00      0.80         6\n",
      "\n",
      "    accuracy                           0.49        35\n",
      "   macro avg       0.56      0.48      0.42        35\n",
      "weighted avg       0.57      0.49      0.43        35\n",
      "\n",
      "human_texts_ksgd-tfidf_10051758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        real       0.00      0.00      0.00         6\n",
      "        fake       0.00      0.00      0.00         5\n",
      "     opinion       0.16      0.83      0.26         6\n",
      "   polarized       0.00      0.00      0.00         6\n",
      "      satire       0.00      0.00      0.00         6\n",
      " promotional       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.17        35\n",
      "   macro avg       0.19      0.17      0.09        35\n",
      "weighted avg       0.20      0.17      0.09        35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tle01/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tle01/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tle01/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tle01/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tle01/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tle01/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tle01/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tle01/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tle01/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tle01/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tle01/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tle01/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tle01/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tle01/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tle01/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for model in model2preds:\n",
    "    preds = model2preds[model]\n",
    "    preds = [preds[url] for url in urls]\n",
    "    report = classification_report(labels, preds, target_names=list(label2idx.values()))\n",
    "    print(model)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c24f0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
